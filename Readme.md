# ğŸ¤– Multimodal PDF Processing & Query System

A sophisticated AI-powered system for processing complex PDF documents containing text, images, and tables, with an intelligent multi-agent query interface.

![System Pipeline](pipeline.png)

## ğŸŒŸ Features

### ğŸ“„ **Advanced PDF Processing**
- **High-resolution document parsing** using Unstructured library
- **Multi-modal content extraction**: Text, images, tables, and figures
- **Parallel processing pipeline** with LangGraph orchestration
- **Semantic text chunking** for optimal retrieval

### ğŸ¤– **Intelligent Multi-Agent System**
- **Supervisor Agent**: Orchestrates query routing and response synthesis
- **Text Analysis Agent**: Handles text-based queries with academic rigor
- **Image Analysis Agent**: Processes visual content and descriptions
- **Table Analysis Agent**: Analyzes structured data and identifies patterns

### ğŸ’¾ **Multi-Modal Storage**
- **Vector Database (ChromaDB)**: Semantic similarity search for text and images
- **SQL Database (SQLite)**: Structured storage for tables and metadata
- **File System**: Original images and detailed metadata preservation

### ğŸ¨ **Modern Web Interface**
- **Streamlit-based UI** with professional styling
- **Real-time agent workflow visualization**
- **Token usage tracking** for cost awareness
- **System health monitoring** with status indicators

![Results Interface](Result.png)

## ğŸ—ï¸ System Architecture

### **Phase 1: Document Processing Pipeline**
```
PDF Input â†’ Parse Document â†’ Extract Content (Parallel)
    â”œâ”€â”€ Images â†’ Describe â†’ Store in Vector DB
    â”œâ”€â”€ Tables â†’ Analyze â†’ Store in SQL DB
    â””â”€â”€ Text â†’ Process â†’ Store in Vector DB
```

### **Phase 2: Multi-Agent Query System**
```
User Query â†’ Supervisor Agent â†’ Route to Specialist
    â”œâ”€â”€ Text Analysis Agent (Vector Retrieval)
    â”œâ”€â”€ Image Analysis Agent (Image Search)
    â””â”€â”€ Table Analysis Agent (SQL Queries)
```

## ğŸš€ Quick Start

### **Prerequisites**
- Docker and Docker Compose
- Groq API Key
- Python 3.11+ (for local development)

### **1. Clone Repository**
```bash
git clone [<repository-url>](https://github.com/DataLunatic69/MultiModel_PDF)
cd datalunatic69-multimodel_pdf
```

### **2. Environment Setup**
Create a `.env` file:
```bash
GROQ_API_KEY=your_groq_api_key_here
MODEL_NAME=llama3-70b-8192
```

### **3. Docker Deployment (Recommended)**

#### **Production Mode**
```bash
# Build and run the application
docker-compose up --build

# Access the application at http://localhost:8501
```

#### **Development Mode**
```bash
# Run with hot reload for development
docker-compose --profile dev up --build

# Access at http://localhost:8502
```

### **4. Local Development**
```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
export GROQ_API_KEY=your_key_here
export MODEL_NAME=llama3-70b-8192

# Process a document
python main.py

# Run Streamlit interface
streamlit run streamlit_app/main.py
```

## ğŸ“– Usage Guide

### **1. Document Processing**
```python
from utilse import process_document, print_summary

# Process a PDF document
result = process_document("path/to/your/document.pdf")

# Print processing summary
if result:
    print_summary(result)
```

### **2. Web Interface**
1. **Upload/Process Documents**: Use the document processing pipeline
2. **Ask Questions**: Natural language queries about your documents
3. **View Responses**: Formatted answers with agent workflow details
4. **Monitor System**: Check component health in the sidebar

### **3. Query Examples**
- **Text Queries**: "What is the main methodology described in this paper?"
- **Image Queries**: "Describe the figures showing the system architecture"
- **Table Queries**: "What are the performance metrics in the results table?"
- **Mixed Queries**: "How do the images relate to the experimental results?"

## ğŸ”§ Configuration

### **Environment Variables**
| Variable | Description | Default |
|----------|-------------|---------|
| `GROQ_API_KEY` | Your Groq API key | Required |
| `MODEL_NAME` | LLM model to use | `llama3-70b-8192` |
| `STREAMLIT_SERVER_PORT` | Web interface port | `8501` |

### **System Settings**
Modify `streamlit_app/config/settings.py` for:
- UI colors and gradients
- Response processing parameters
- Token usage limits
- Agent prompts and behavior

## ğŸ“ Project Structure

```
Directory structure:
â””â”€â”€ datalunatic69-multimodel_pdf/
    â”œâ”€â”€ Readme.md
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ model.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ utilse.py
    â”œâ”€â”€ .env.example
    â”œâ”€â”€ chatbot/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ interface.py
    â”‚   â”œâ”€â”€ main.py
    â”‚   â”œâ”€â”€ model.py
    â”‚   â”œâ”€â”€ subagents/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ image_analysis_agent.py
    â”‚   â”‚   â”œâ”€â”€ table_analysis_agent.py
    â”‚   â”‚   â””â”€â”€ text_analysis_agent.py
    â”‚   â”œâ”€â”€ tools/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ database_tool.py
    â”‚   â”‚   â”œâ”€â”€ image_description_retriever_tool.py
    â”‚   â”‚   â””â”€â”€ text_retriever_tool.py
    â”‚   â””â”€â”€ utilise/
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ image_helper.py
    â”‚       â””â”€â”€ text_helper.py
    â”œâ”€â”€ Dockerfiles/
    â”‚   â”œâ”€â”€ docker_compose.yml
    â”‚   â”œâ”€â”€ dockerfile
    â”‚   â””â”€â”€ .dockerignore
    â”œâ”€â”€ docs/
    â”‚   â””â”€â”€ Architecture.md
    â”œâ”€â”€ knowledge_creation/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ store_image.py
    â”‚   â”œâ”€â”€ store_table.py
    â”‚   â””â”€â”€ store_text.py
    â”œâ”€â”€ nodes/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ parsing_document_node.py
    â”‚   â”œâ”€â”€ image_nodes/
    â”‚   â”‚   â”œâ”€â”€ __init.py
    â”‚   â”‚   â”œâ”€â”€ describe_image_node.py
    â”‚   â”‚   â””â”€â”€ image_extrator_node.py
    â”‚   â”œâ”€â”€ table_nodes/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ describe_table_node.py
    â”‚   â”‚   â””â”€â”€ table_extractor_node.py
    â”‚   â””â”€â”€ text_nodes/
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ describe_text_node.py
    â”‚       â””â”€â”€ text_extractor_node.py
    â”œâ”€â”€ orchestration/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ states.py
    â”‚   â””â”€â”€ workflows.py
    â””â”€â”€ streamlit_app/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ app.py
        â”œâ”€â”€ components/
        â”‚   â”œâ”€â”€ __init__.py
        â”‚   â”œâ”€â”€ chat_interface.py
        â”‚   â”œâ”€â”€ response_utils.py
        â”‚   â”œâ”€â”€ sidebar.py
        â”‚   â””â”€â”€ styles.py
        â””â”€â”€ utils/
            â”œâ”€â”€ __init__.py
            â”œâ”€â”€ agents.py
            â””â”€â”€ logging.py

```

## ğŸ§  Technology Stack

### **Core Technologies**
- **ğŸ Python 3.11**: Primary language
- **ğŸ¦œ LangChain**: LLM orchestration framework
- **ğŸ“Š LangGraph**: Workflow state management
- **ğŸš€ Groq**: Fast LLM inference
- **ğŸ¨ Streamlit**: Web interface framework

### **Document Processing**
- **ğŸ“„ Unstructured**: Advanced PDF parsing
- **ğŸ–¼ï¸ PIL/OpenCV**: Image processing
- **ğŸ“Š Pandas**: Data manipulation

### **Storage & Retrieval**
- **ğŸ” ChromaDB**: Vector database
- **ğŸ—„ï¸ SQLite**: Relational database
- **ğŸ¤— HuggingFace**: Text embeddings
- **ğŸ”¢ Sentence Transformers**: Semantic similarity

### **Infrastructure**
- **ğŸ³ Docker**: Containerization
- **ğŸ”§ Docker Compose**: Multi-service orchestration
- **ğŸ“‹ Logging**: Structured application logging

## ğŸ”’ Security & Privacy

- **ğŸ  Local Processing**: All data processed locally
- **ğŸ” No External APIs**: For document content (only LLM inference)
- **ğŸ“ Isolated Storage**: Containerized data handling
- **ğŸ›¡ï¸ Environment Variables**: Secure credential management

## ğŸ“ˆ Performance Characteristics

- **âš¡ Processing Speed**: 2-5 minutes for typical academic papers
- **ğŸ’¾ Memory Usage**: Optimized for 8GB+ RAM systems
- **ğŸ” Query Response**: Sub-second for most queries
- **ğŸ“Š Throughput**: Handles documents up to 50MB efficiently

## ğŸ”§ Development

### **Adding New Features**
1. **New Agents**: Create in `chatbot/subagents/`
2. **UI Components**: Add to `streamlit_app/components/`
3. **Processing Nodes**: Implement in `nodes/`
4. **Storage Systems**: Extend `knowledge_creation/`

### **Debugging**
- **Logs**: Check Docker logs with `docker-compose logs`
- **Health Checks**: Monitor system status in sidebar
- **Agent Flow**: View workflow in response metadata

### **Testing**
```bash
# Run tests
pytest tests/

# Test document processing
python main.py

# Test chatbot
python chatbot/main.py
```

## ğŸš¨ Troubleshooting

### **Common Issues**

#### **Docker Build Fails**
```bash
# Clean build
docker-compose down
docker system prune -a
docker-compose up --build
```

#### **Environment Variables Not Set**
```bash
# Check variables
docker-compose config

# Set in .env file
echo "GROQ_API_KEY=your_key" > .env
echo "MODEL_NAME=llama3-70b-8192" >> .env
```

#### **Vector Store Issues**
```bash
# Reset vector stores
rm -rf text_vector_store image_vector_store
docker-compose restart
```

#### **Memory Issues**
```bash
# Increase Docker memory limit
# Docker Desktop > Settings > Resources > Memory: 8GB+
```

## ğŸ›£ï¸ Roadmap

### **ğŸ”® Future Enhancements**
- **ğŸ”„ Hierarchical Chunking**: Advanced image description segmentation
- **âš¡ Late Chunking**: Global token context for better text processing
- **ğŸŒ Multi-Document**: Cross-document analysis and comparison
- **ğŸ¯ Fine-tuning**: Domain-specific model optimization
- **ğŸ“Š Analytics**: Advanced document insights and patterns
- **ğŸ”Œ API**: RESTful API for external integrations

## ğŸ“ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“§ Support

For issues and questions:
- ğŸ› **Bug Reports**: Create an issue on GitHub
- ğŸ’¡ **Feature Requests**: Discussion in GitHub Issues
- ğŸ“– **Documentation**: Check `docs/Architecture.md`
- ğŸ”§ **Development**: See development guidelines above

## ğŸ™ Acknowledgments

- **ğŸ¦œ LangChain Team**: For the excellent LLM framework
- **ğŸ“„ Unstructured**: For advanced document processing capabilities
- **ğŸ¤— HuggingFace**: For embeddings and model ecosystem
- **ğŸš€ Groq**: For fast LLM inference
- **ğŸ¨ Streamlit**: For the intuitive web framework

---

**ğŸš€ Ready to process your documents intelligently?**

Start with `docker-compose up --build` and visit http://localhost:8501
