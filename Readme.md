# ğŸ¤– Multimodal PDF Processing & Query System

A sophisticated AI-powered system for processing complex PDF documents containing text, images, and tables, with an intelligent multi-agent query interface.

![System Pipeline](pipeline.png)

## ğŸŒŸ Features

### ğŸ“„ **Advanced PDF Processing**
- **High-resolution document parsing** using Unstructured library
- **Multi-modal content extraction**: Text, images, tables, and figures
- **Parallel processing pipeline** with LangGraph orchestration
- **Semantic text chunking** for optimal retrieval

### ğŸ¤– **Intelligent Multi-Agent System**
- **Supervisor Agent**: Orchestrates query routing and response synthesis
- **Text Analysis Agent**: Handles text-based queries with academic rigor
- **Image Analysis Agent**: Processes visual content and descriptions
- **Table Analysis Agent**: Analyzes structured data and identifies patterns

### ğŸ’¾ **Multi-Modal Storage**
- **Vector Database (ChromaDB)**: Semantic similarity search for text and images
- **SQL Database (SQLite)**: Structured storage for tables and metadata
- **File System**: Original images and detailed metadata preservation

### ğŸ¨ **Modern Web Interface**
- **Streamlit-based UI** with professional styling
- **Real-time agent workflow visualization**
- **Token usage tracking** for cost awareness
- **System health monitoring** with status indicators

![Results Interface](result.png)

## ğŸ—ï¸ System Architecture

### **Phase 1: Document Processing Pipeline**
```
PDF Input â†’ Parse Document â†’ Extract Content (Parallel)
    â”œâ”€â”€ Images â†’ Describe â†’ Store in Vector DB
    â”œâ”€â”€ Tables â†’ Analyze â†’ Store in SQL DB
    â””â”€â”€ Text â†’ Process â†’ Store in Vector DB
```

### **Phase 2: Multi-Agent Query System**
```
User Query â†’ Supervisor Agent â†’ Route to Specialist
    â”œâ”€â”€ Text Analysis Agent (Vector Retrieval)
    â”œâ”€â”€ Image Analysis Agent (Image Search)
    â””â”€â”€ Table Analysis Agent (SQL Queries)
```

## ğŸš€ Quick Start

### **Prerequisites**
- Docker and Docker Compose
- Groq API Key
- Python 3.11+ (for local development)

### **1. Clone Repository**
```bash
git clone <repository-url>
cd datalunatic69-multimodel_pdf
```

### **2. Environment Setup**
Create a `.env` file:
```bash
GROQ_API_KEY=your_groq_api_key_here
MODEL_NAME=llama3-70b-8192
```

### **3. Docker Deployment (Recommended)**

#### **Production Mode**
```bash
# Build and run the application
docker-compose up --build

# Access the application at http://localhost:8501
```

#### **Development Mode**
```bash
# Run with hot reload for development
docker-compose --profile dev up --build

# Access at http://localhost:8502
```

### **4. Local Development**
```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
export GROQ_API_KEY=your_key_here
export MODEL_NAME=llama3-70b-8192

# Process a document
python main.py

# Run Streamlit interface
streamlit run streamlit_app/main.py
```

## ğŸ“– Usage Guide

### **1. Document Processing**
```python
from utilse import process_document, print_summary

# Process a PDF document
result = process_document("path/to/your/document.pdf")

# Print processing summary
if result:
    print_summary(result)
```

### **2. Web Interface**
1. **Upload/Process Documents**: Use the document processing pipeline
2. **Ask Questions**: Natural language queries about your documents
3. **View Responses**: Formatted answers with agent workflow details
4. **Monitor System**: Check component health in the sidebar

### **3. Query Examples**
- **Text Queries**: "What is the main methodology described in this paper?"
- **Image Queries**: "Describe the figures showing the system architecture"
- **Table Queries**: "What are the performance metrics in the results table?"
- **Mixed Queries**: "How do the images relate to the experimental results?"

## ğŸ”§ Configuration

### **Environment Variables**
| Variable | Description | Default |
|----------|-------------|---------|
| `GROQ_API_KEY` | Your Groq API key | Required |
| `MODEL_NAME` | LLM model to use | `llama3-70b-8192` |
| `STREAMLIT_SERVER_PORT` | Web interface port | `8501` |

### **System Settings**
Modify `streamlit_app/config/settings.py` for:
- UI colors and gradients
- Response processing parameters
- Token usage limits
- Agent prompts and behavior

## ğŸ“ Project Structure

```
datalunatic69-multimodel_pdf/
â”œâ”€â”€ ğŸ³ Docker Configuration
â”‚   â”œâ”€â”€ Dockerfile                   # Main container definition
â”‚   â”œâ”€â”€ docker-compose.yml           # Multi-service orchestration
â”‚   â””â”€â”€ .dockerignore               # Docker build exclusions
â”œâ”€â”€ ğŸ“„ Core Processing
â”‚   â”œâ”€â”€ main.py                     # Document processing entry point
â”‚   â”œâ”€â”€ utilse.py                   # Processing utilities
â”‚   â”œâ”€â”€ model.py                    # LLM initialization
â”‚   â””â”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ ğŸ¤– Chatbot System
â”‚   â””â”€â”€ chatbot/
â”‚       â”œâ”€â”€ interface.py            # Agent interface
â”‚       â”œâ”€â”€ main.py                 # Supervisor agent
â”‚       â”œâ”€â”€ model.py                # Model management
â”‚       â”œâ”€â”€ subagents/              # Specialist agents
â”‚       â”œâ”€â”€ tools/                  # Retrieval tools
â”‚       â””â”€â”€ utilise/                # Helper utilities
â”œâ”€â”€ ğŸ¨ Web Interface
â”‚   â””â”€â”€ streamlit_app/
â”‚       â”œâ”€â”€ main.py                 # Application entry point
â”‚       â”œâ”€â”€ config/                 # Configuration settings
â”‚       â”œâ”€â”€ core/                   # Core functionality
â”‚       â”œâ”€â”€ components/             # UI components
â”‚       â””â”€â”€ utils/                  # Utility functions
â”œâ”€â”€ ğŸ”„ Processing Pipeline
â”‚   â”œâ”€â”€ nodes/                      # Processing nodes
â”‚   â”œâ”€â”€ orchestration/              # Workflow management
â”‚   â””â”€â”€ knowledge_creation/         # Storage systems
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ docs/Architecture.md        # System architecture
    â””â”€â”€ README.md                   # This file
```

## ğŸ§  Technology Stack

### **Core Technologies**
- **ğŸ Python 3.11**: Primary language
- **ğŸ¦œ LangChain**: LLM orchestration framework
- **ğŸ“Š LangGraph**: Workflow state management
- **ğŸš€ Groq**: Fast LLM inference
- **ğŸ¨ Streamlit**: Web interface framework

### **Document Processing**
- **ğŸ“„ Unstructured**: Advanced PDF parsing
- **ğŸ–¼ï¸ PIL/OpenCV**: Image processing
- **ğŸ“Š Pandas**: Data manipulation

### **Storage & Retrieval**
- **ğŸ” ChromaDB**: Vector database
- **ğŸ—„ï¸ SQLite**: Relational database
- **ğŸ¤— HuggingFace**: Text embeddings
- **ğŸ”¢ Sentence Transformers**: Semantic similarity

### **Infrastructure**
- **ğŸ³ Docker**: Containerization
- **ğŸ”§ Docker Compose**: Multi-service orchestration
- **ğŸ“‹ Logging**: Structured application logging

## ğŸ”’ Security & Privacy

- **ğŸ  Local Processing**: All data processed locally
- **ğŸ” No External APIs**: For document content (only LLM inference)
- **ğŸ“ Isolated Storage**: Containerized data handling
- **ğŸ›¡ï¸ Environment Variables**: Secure credential management

## ğŸ“ˆ Performance Characteristics

- **âš¡ Processing Speed**: 2-5 minutes for typical academic papers
- **ğŸ’¾ Memory Usage**: Optimized for 8GB+ RAM systems
- **ğŸ” Query Response**: Sub-second for most queries
- **ğŸ“Š Throughput**: Handles documents up to 50MB efficiently

## ğŸ”§ Development

### **Adding New Features**
1. **New Agents**: Create in `chatbot/subagents/`
2. **UI Components**: Add to `streamlit_app/components/`
3. **Processing Nodes**: Implement in `nodes/`
4. **Storage Systems**: Extend `knowledge_creation/`

### **Debugging**
- **Logs**: Check Docker logs with `docker-compose logs`
- **Health Checks**: Monitor system status in sidebar
- **Agent Flow**: View workflow in response metadata

### **Testing**
```bash
# Run tests
pytest tests/

# Test document processing
python main.py

# Test chatbot
python chatbot/main.py
```

## ğŸš¨ Troubleshooting

### **Common Issues**

#### **Docker Build Fails**
```bash
# Clean build
docker-compose down
docker system prune -a
docker-compose up --build
```

#### **Environment Variables Not Set**
```bash
# Check variables
docker-compose config

# Set in .env file
echo "GROQ_API_KEY=your_key" > .env
echo "MODEL_NAME=llama3-70b-8192" >> .env
```

#### **Vector Store Issues**
```bash
# Reset vector stores
rm -rf text_vector_store image_vector_store
docker-compose restart
```

#### **Memory Issues**
```bash
# Increase Docker memory limit
# Docker Desktop > Settings > Resources > Memory: 8GB+
```

## ğŸ›£ï¸ Roadmap

### **ğŸ”® Future Enhancements**
- **ğŸ”„ Hierarchical Chunking**: Advanced image description segmentation
- **âš¡ Late Chunking**: Global token context for better text processing
- **ğŸŒ Multi-Document**: Cross-document analysis and comparison
- **ğŸ¯ Fine-tuning**: Domain-specific model optimization
- **ğŸ“Š Analytics**: Advanced document insights and patterns
- **ğŸ”Œ API**: RESTful API for external integrations

## ğŸ“ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“§ Support

For issues and questions:
- ğŸ› **Bug Reports**: Create an issue on GitHub
- ğŸ’¡ **Feature Requests**: Discussion in GitHub Issues
- ğŸ“– **Documentation**: Check `docs/Architecture.md`
- ğŸ”§ **Development**: See development guidelines above

## ğŸ™ Acknowledgments

- **ğŸ¦œ LangChain Team**: For the excellent LLM framework
- **ğŸ“„ Unstructured**: For advanced document processing capabilities
- **ğŸ¤— HuggingFace**: For embeddings and model ecosystem
- **ğŸš€ Groq**: For fast LLM inference
- **ğŸ¨ Streamlit**: For the intuitive web framework

---

**ğŸš€ Ready to process your documents intelligently?**

Start with `docker-compose up --build` and visit http://localhost:8501